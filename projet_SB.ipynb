{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy.random import multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#networks simulation\n",
    "N = 100\n",
    "D0 = np.random.randint(2,size=(N,N))\n",
    "D1 = np.random.randint(2,size=(N,N))\n",
    "for i in range(N):\n",
    "    D0[i,i] = 0\n",
    "    D1[i,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = np.sum(D0,axis=1)\n",
    "G0 = np.linalg.solve(np.diag(M0),D0)\n",
    "\n",
    "M1 = np.sum(D1,axis=1)\n",
    "G1 = np.linalg.solve(np.diag(M1),D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "F0 = (np.dot(D0,D0)>0).astype(np.int)\n",
    "F1 = (np.dot(D1,D1)>0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPA simulation\n",
    "gpa_0 = np.random.uniform(low= 0,high=4,size=N)\n",
    "gpa_1 = np.random.uniform(low=0,high=4,size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MLIM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait la régression bayésienne, avec les a posteriori conjugués (inverse-$\\chi^2(1)$, normale conditionnelle).\n",
    "\n",
    "si on veut juste les means et vars, il suffit de les calculer les paramètres des posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#priors \n",
    "#on a 4 coefficients beta sur lesquels travailler \n",
    "mu0 = np.zeros(4) #mean of the conditional normal distribution \n",
    "Q0 = np.diag(np.ones(4)) #var of the conditional normal distribution\n",
    "a0 = 1 #coef of the inverse gamma\n",
    "b0 = 1 #scaling coefficient of the inverse gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construction des variables explicatives et variables cibles\n",
    "Y = gpa_1\n",
    "Ybar = G1.dot(Y)\n",
    "X = gpa_0\n",
    "Xbar = G1.dot(X)\n",
    "features = np.column_stack((np.ones(len(Y)),Ybar,X,Xbar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres du modèle sont mis à jour selon les équations suivantes :\n",
    "$$ Q_{n}=(\\mathbf {X} ^{\\rm {T}}\\mathbf {X} + Q_{0}) $$\n",
    "$$  \\boldsymbol\\mu_n=(\\mathbf{X}^{\\rm T}\\mathbf{X}+ Q_0)^{-1} (Q_0\\boldsymbol\\mu_0+\\mathbf{X}^{\\rm T}\\mathbf{y})  $$ \n",
    "$$ a_{n}=a_{0}+{\\frac  {n}{2}} $$ \n",
    "$$ b_{n}=b_{0}+{\\frac  {1}{2}}({\\mathbf  {y}}^{{{\\rm {T}}}}{\\mathbf  {y}}+{\\boldsymbol  \\mu }_{0}^{{{\\rm {T}}}}Q_{0}{\\boldsymbol  \\mu }_{0}-{\\boldsymbol  \\mu }_{n}^{{{\\rm {T}}}}Q_{n}{\\boldsymbol  \\mu }_{n}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating parameters: computing the posterior distribution parameters\n",
    "Qn = features.T.dot(features) + Q0\n",
    "mun = np.linalg.solve(Qn,Q0.dot(mu0)+features.T.dot(Y))\n",
    "an = a0+len(Y)/2\n",
    "bn = b0 + 0.5*(Y.dot(Y)+mu0.T.dot(Q0.dot(mu0))-mun.T.dot(Qn.dot(mun)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.46692776,  0.42632134,  0.16548153, -0.35156051])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#moyennes des lois normales a posteriori\n",
    "mun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient donc \n",
    "$$ \\beta_0 = 1.46 , \\beta_{\\bar{Y}} = 0.42, \\beta_x = 0.16, \\beta_{\\bar{x}} = -0.35 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101.        , 192.73912912, 198.45645215, 199.66130908],\n",
       "       [192.73912912, 373.77063606, 380.04142165, 385.00817177],\n",
       "       [198.45645215, 380.04142165, 545.17215733, 392.69089827],\n",
       "       [199.66130908, 385.00817177, 392.69089827, 401.00271555]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrice de variance covariance\n",
    "Qn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce résultat est étrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2081525826648845"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn/(an-1) #moyenne de l'inverse-gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0297884216938741"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn**2/((an-1)**2*(an-2)) #variance de l'inverse gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exogenous network formation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha \\sim \\mathcal{N}(0,1)$ (chaque \\alpha suit une loi normale de façon indépendante)\n",
    "\n",
    "$P(D_{ij} = 1|D_{0},X)  = \\frac{e^{\\alpha_{0} + \\alpha_{x}|Xi-Xj| + \\alpha_{d}D_{0ij}+ \\alpha_{f}F_{0ij}}}{1 + e^{\\alpha_{0} + \\alpha_{x}|Xi-Xj| + \\alpha_{d}D_{0ij}+ \\alpha_{f}F_{0ij}}}$\n",
    "\n",
    "=> cas conjugué?\n",
    "\n",
    "à déterminer: posterior (à calculer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#priors\n",
    "alpha0 = np.random.randn(1)\n",
    "alphax = np.random.randn(1)\n",
    "alphad = np.random.randn(1)\n",
    "alphaf = np.random.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering \n",
    "#we must create |Xi-Xj| for each (i,j) couple \n",
    "dist = np.zeros((N,N))\n",
    "for i in range(N):\n",
    "    for j in range(i,N):\n",
    "        value = np.abs(X[i]-X[j])\n",
    "        dist[i][j] = value\n",
    "        dist[j][i] = value\n",
    "#We create a new D1 matrix based on the probability formula\n",
    "D1_new = np.zeros((N,N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        U = np.exp(alpha0 + alphax*dist[i][j] + alphad*D0[i][j] + alphaf*F0[i][j])\n",
    "        p = (U)/(1 + U)\n",
    "        D1_new[i][j] = np.random.binomial(1,p**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Endogenous network formation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aller voir appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Heterogeneity in peer effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as 1. with different networks and extended models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
